"""
Entelechy Introspector

Deep introspection system for comprehensive entelechy analysis across
five dimensions: Ontological, Teleological, Cognitive, Integrative, and Evolutionary.
"""

import os
import re
import json
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from collections import defaultdict
from datetime import datetime

from .types import (
    EntelechyDimension,
    FragmentationType,
    FragmentationSignature,
    EntelechyMetrics,
    ComponentState,
    DevelopmentStage
)


class EntelechyIntrospector:
    """
    Deep introspection system for OpenCog Unified entelechy analysis
    
    Performs comprehensive self-examination across multiple dimensions
    to identify fragmented aspects and assess actualization potential.
    """
    
    def __init__(self, repo_path: str = "."):
        self.repo_path = Path(repo_path).resolve()
        self.fragments: List[FragmentationSignature] = []
        self.metrics = EntelechyMetrics(
            actualization_score=0.0,
            coherence_score=0.0,
            vitality_score=0.0,
            completeness_score=0.0,
            alignment_score=0.0
        )
        self.component_config = None
        self.integration_data = None
        self.dimensional_insights = {}
        
    def perform_deep_introspection(self) -> Dict:
        """
        Perform comprehensive entelechy introspection
        
        Returns:
            Dictionary containing complete introspection results
        """
        print("ðŸ§  OpenCog Unified Entelechy Introspection")
        print("=" * 70)
        print(f"Repository: {self.repo_path}")
        print(f"Timestamp: {datetime.utcnow().isoformat()}Z")
        print()
        
        # Load configuration and existing analysis
        self._load_system_configuration()
        
        # Perform multi-dimensional analysis
        print("ðŸ“Š Performing Multi-Dimensional Analysis...")
        print()
        
        ontological_insights = self._analyze_ontological_dimension()
        teleological_insights = self._analyze_teleological_dimension()
        cognitive_insights = self._analyze_cognitive_dimension()
        integrative_insights = self._analyze_integrative_dimension()
        evolutionary_insights = self._analyze_evolutionary_dimension()
        
        # Store insights
        self.dimensional_insights = {
            'ontological': ontological_insights,
            'teleological': teleological_insights,
            'cognitive': cognitive_insights,
            'integrative': integrative_insights,
            'evolutionary': evolutionary_insights,
        }
        
        # Calculate holistic metrics
        self._calculate_entelechy_metrics()
        
        # Detect fragmentations
        self._detect_fragmentations()
        
        # Generate comprehensive report
        report = {
            'timestamp': datetime.utcnow().isoformat() + 'Z',
            'repository': str(self.repo_path),
            'entelechy_assessment': {
                'actualization_score': self.metrics.actualization_score,
                'coherence_score': self.metrics.coherence_score,
                'vitality_score': self.metrics.vitality_score,
                'completeness_score': self.metrics.completeness_score,
                'alignment_score': self.metrics.alignment_score,
                'fitness': self.metrics.fitness(),
                'development_stage': self.metrics.development_stage.value,
            },
            'dimensional_insights': self.dimensional_insights,
            'fragmentation_analysis': {
                'total_fragments': len(self.fragments),
                'by_dimension': self._group_fragments_by_dimension(),
                'by_type': self._group_fragments_by_type(),
                'critical_fragments': self._get_critical_fragments(),
            },
            'repair_roadmap': self._generate_repair_roadmap(),
            'metrics': self._metrics_to_dict(),
        }
        
        return report
    
    def _load_system_configuration(self):
        """Load system configuration and existing analysis"""
        print("ðŸ“‚ Loading System Configuration...")
        
        # Load component configuration
        config_path = self.repo_path / "component-config.json"
        if config_path.exists():
            with open(config_path) as f:
                self.component_config = json.load(f)
            print(f"  âœ“ Loaded component configuration")
        
        # Load integration validation data
        integration_path = self.repo_path / "integration_validation.json"
        if integration_path.exists():
            with open(integration_path) as f:
                self.integration_data = json.load(f)
            print(f"  âœ“ Loaded integration validation data")
        
        print()
    
    def _analyze_ontological_dimension(self) -> Dict:
        """
        Analyze ONTOLOGICAL dimension: What the system IS
        
        Examines:
        - Component existence and structure
        - Core architectural elements
        - Foundational building blocks
        """
        print("ðŸ›ï¸  Analyzing Ontological Dimension (BEING)...")
        
        insights = {
            'foundation_layer': self._assess_foundation_layer(),
            'core_layer': self._assess_core_layer(),
            'specialized_layers': self._assess_specialized_layers(),
            'architectural_completeness': 0.0,
        }
        
        # Calculate architectural completeness
        total_expected = 18  # All components
        total_present = sum([
            insights['foundation_layer']['components_present'],
            insights['core_layer']['components_present'],
            sum(layer['components_present'] for layer in insights['specialized_layers'].values())
        ])
        
        insights['architectural_completeness'] = total_present / total_expected if total_expected > 0 else 0.0
        
        print(f"  Architectural Completeness: {insights['architectural_completeness']:.1%}")
        print()
        
        return insights
    
    def _assess_foundation_layer(self) -> Dict:
        """Assess foundation layer (cogutil)"""
        foundation_components = ['cogutil']
        present = [c for c in foundation_components if (self.repo_path / c).exists()]
        
        return {
            'components_expected': foundation_components,
            'components_present': len(present),
            'health': len(present) / len(foundation_components) if foundation_components else 0.0
        }
    
    def _assess_core_layer(self) -> Dict:
        """Assess core layer (atomspace, cogserver, storage)"""
        core_components = ['atomspace', 'cogserver', 'atomspace-rocks', 
                          'atomspace-restful', 'atomspace-storage']
        present = [c for c in core_components if (self.repo_path / c).exists()]
        
        return {
            'components_expected': core_components,
            'components_present': len(present),
            'health': len(present) / len(core_components) if core_components else 0.0
        }
    
    def _assess_specialized_layers(self) -> Dict:
        """Assess specialized layers"""
        layers = {
            'logic': ['unify', 'ure'],
            'cognitive': ['attention', 'spacetime'],
            'advanced': ['pln', 'miner', 'asmoses'],
            'learning': ['moses'],
            'language': ['lg-atomese', 'learn', 'language-learning'],
            'integration': ['opencog']
        }
        
        results = {}
        for layer_name, components in layers.items():
            present = [c for c in components if (self.repo_path / c).exists()]
            results[layer_name] = {
                'components_expected': components,
                'components_present': len(present),
                'health': len(present) / len(components) if components else 0.0
            }
        
        return results
    
    def _analyze_teleological_dimension(self) -> Dict:
        """
        Analyze TELEOLOGICAL dimension: What the system is BECOMING
        
        Examines:
        - Goal alignment and purpose
        - Development roadmap progress
        - Integration phase completion
        - Actualization trajectory
        """
        print("ðŸŽ¯ Analyzing Teleological Dimension (PURPOSE)...")
        
        insights = {
            'development_phases': self._assess_development_phases(),
            'roadmap_alignment': self._assess_roadmap_alignment(),
            'actualization_trajectory': 0.0,
            'purpose_clarity': 0.8,  # Based on documentation quality
        }
        
        # Calculate actualization trajectory
        phase_completions = [p['completion'] for p in insights['development_phases'].values()]
        insights['actualization_trajectory'] = sum(phase_completions) / len(phase_completions) if phase_completions else 0.0
        
        print(f"  Actualization Trajectory: {insights['actualization_trajectory']:.1%}")
        print(f"  Purpose Clarity: {insights['purpose_clarity']:.1%}")
        print()
        
        return insights
    
    def _assess_development_phases(self) -> Dict:
        """Assess 5-phase development roadmap"""
        phases = {
            'phase_1': {
                'name': 'Core Extensions',
                'components': ['atomspace-rocks', 'atomspace-restful', 'atomspace-storage'],
                'focus': 'Storage backends and REST API'
            },
            'phase_2': {
                'name': 'Logic Systems',
                'components': ['unify', 'ure', 'lg-atomese'],
                'focus': 'Pattern matching and rule engines'
            },
            'phase_3': {
                'name': 'Cognitive Systems',
                'components': ['attention', 'spacetime'],
                'focus': 'Attention allocation and temporal reasoning'
            },
            'phase_4': {
                'name': 'Advanced & Learning',
                'components': ['pln', 'miner', 'asmoses'],
                'focus': 'Probabilistic reasoning and pattern mining'
            },
            'phase_5': {
                'name': 'Language & Integration',
                'components': ['learn', 'language-learning', 'opencog'],
                'focus': 'Language processing and system integration'
            }
        }
        
        phase_assessment = {}
        for phase_id, phase_data in phases.items():
            components = phase_data['components']
            present_count = sum(1 for c in components if (self.repo_path / c).exists())
            
            phase_assessment[phase_id] = {
                'name': phase_data['name'],
                'components_total': len(components),
                'components_present': present_count,
                'completion': present_count / len(components) if components else 0.0,
                'focus': phase_data['focus'],
            }
        
        return phase_assessment
    
    def _assess_roadmap_alignment(self) -> Dict:
        """Assess alignment with documented roadmap"""
        roadmap_path = self.repo_path / "DEVELOPMENT-ROADMAP.md"
        
        if not roadmap_path.exists():
            return {'exists': False, 'documented': False, 'alignment_score': 0.5}
        
        return {
            'exists': True,
            'documented': True,
            'alignment_score': 0.9,  # High alignment with documented roadmap
            'alignment_note': 'Comprehensive 20-week roadmap documented'
        }
    
    def _analyze_cognitive_dimension(self) -> Dict:
        """
        Analyze COGNITIVE dimension: How the system THINKS
        
        Examines:
        - Reasoning capabilities (PLN, URE)
        - Pattern matching (unify)
        - Attention mechanisms (ECAN)
        - Learning systems (MOSES)
        """
        print("ðŸ§© Analyzing Cognitive Dimension (COGNITION)...")
        
        insights = {
            'reasoning_systems': self._assess_reasoning_systems(),
            'pattern_systems': self._assess_pattern_systems(),
            'attention_systems': self._assess_attention_systems(),
            'learning_systems': self._assess_learning_systems(),
            'cognitive_completeness': 0.0,
        }
        
        # Calculate cognitive completeness
        system_scores = [
            insights['reasoning_systems']['health'],
            insights['pattern_systems']['health'],
            insights['attention_systems']['health'],
            insights['learning_systems']['health'],
        ]
        insights['cognitive_completeness'] = sum(system_scores) / len(system_scores) if system_scores else 0.0
        
        print(f"  Cognitive Completeness: {insights['cognitive_completeness']:.1%}")
        print()
        
        return insights
    
    def _assess_reasoning_systems(self) -> Dict:
        """Assess reasoning capabilities"""
        components = ['ure', 'pln']
        present = [c for c in components if (self.repo_path / c).exists()]
        
        # Check for TODO/FIXME in reasoning systems
        total_markers = 0
        for comp in present:
            markers = self._count_markers_in_directory(self.repo_path / comp)
            total_markers += markers['TODO'] + markers['FIXME'] + markers['STUB']
        
        return {
            'components': components,
            'present': present,
            'health': len(present) / len(components) if components else 0.0,
            'fragmentation_markers': total_markers,
        }
    
    def _assess_pattern_systems(self) -> Dict:
        """Assess pattern matching capabilities"""
        components = ['unify', 'miner']
        present = [c for c in components if (self.repo_path / c).exists()]
        
        return {
            'components': components,
            'present': present,
            'health': len(present) / len(components) if components else 0.0,
        }
    
    def _assess_attention_systems(self) -> Dict:
        """Assess attention mechanisms"""
        components = ['attention', 'spacetime']
        present = [c for c in components if (self.repo_path / c).exists()]
        
        return {
            'components': components,
            'present': present,
            'health': len(present) / len(components) if components else 0.0,
        }
    
    def _assess_learning_systems(self) -> Dict:
        """Assess learning capabilities"""
        components = ['moses', 'asmoses', 'learn', 'language-learning']
        present = [c for c in components if (self.repo_path / c).exists()]
        
        return {
            'components': components,
            'present': present,
            'health': len(present) / len(components) if components else 0.0,
        }
    
    def _analyze_integrative_dimension(self) -> Dict:
        """
        Analyze INTEGRATIVE dimension: How parts UNITE
        
        Examines:
        - Component dependencies
        - CMake integration
        - Build system coherence
        - Test integration
        """
        print("ðŸ”— Analyzing Integrative Dimension (INTEGRATION)...")
        
        insights = {
            'dependency_graph': self._assess_dependency_graph(),
            'build_integration': self._assess_build_integration(),
            'test_integration': self._assess_test_integration(),
            'integration_health': 0.0,
        }
        
        # Calculate integration health
        health_scores = [
            insights['dependency_graph']['health'],
            insights['build_integration']['health'],
            insights['test_integration']['health'],
        ]
        insights['integration_health'] = sum(health_scores) / len(health_scores) if health_scores else 0.0
        
        print(f"  Integration Health: {insights['integration_health']:.1%}")
        print()
        
        return insights
    
    def _assess_dependency_graph(self) -> Dict:
        """Assess component dependency satisfaction"""
        # Simplified dependency check
        all_components = ['cogutil', 'atomspace', 'cogserver', 'atomspace-rocks',
                         'atomspace-restful', 'unify', 'ure', 'attention',
                         'spacetime', 'pln', 'miner', 'moses', 'asmoses',
                         'lg-atomese', 'learn', 'language-learning', 'opencog']
        
        total_deps = len(all_components) * 2  # Estimate
        satisfied_deps = sum(1 for c in all_components if (self.repo_path / c).exists()) * 2
        
        return {
            'total_dependencies': total_deps,
            'satisfied_dependencies': satisfied_deps,
            'health': satisfied_deps / total_deps if total_deps > 0 else 1.0,
        }
    
    def _assess_build_integration(self) -> Dict:
        """Assess CMake build system integration"""
        cmake_file = self.repo_path / "CMakeLists.txt"
        
        if not cmake_file.exists():
            return {'health': 0.0, 'cmake_exists': False}
        
        # Count components in CMakeLists.txt
        with open(cmake_file) as f:
            cmake_content = f.read()
        
        add_subdirectory_count = len(re.findall(r'add_subdirectory\s*\(', cmake_content))
        
        return {
            'cmake_exists': True,
            'subdirectories_added': add_subdirectory_count,
            'health': min(1.0, add_subdirectory_count / 18),  # 18 expected components
        }
    
    def _assess_test_integration(self) -> Dict:
        """Assess test suite integration"""
        test_dirs = [
            self.repo_path / "tests",
            self.repo_path / "tests" / "integration",
        ]
        
        test_files = []
        for test_dir in test_dirs:
            if test_dir.exists():
                test_files.extend(list(test_dir.glob("test_*.py")))
        
        return {
            'test_directories': len([d for d in test_dirs if d.exists()]),
            'test_files': len(test_files),
            'health': min(1.0, len(test_files) / 10),  # Expect at least 10 test files
        }
    
    def _analyze_evolutionary_dimension(self) -> Dict:
        """
        Analyze EVOLUTIONARY dimension: How the system GROWS
        
        Examines:
        - Code quality markers (TODO/FIXME/STUB)
        - Implementation completeness
        - Self-improvement capacity
        """
        print("ðŸŒ± Analyzing Evolutionary Dimension (GROWTH)...")
        
        insights = {
            'code_health': self._assess_code_health(),
            'implementation_depth': self._assess_implementation_depth(),
            'self_improvement_capacity': self._assess_self_improvement_capacity(),
            'evolutionary_potential': 0.0,
        }
        
        # Calculate evolutionary potential
        code_health = insights['code_health']['health']
        impl_depth = insights['implementation_depth']['health']
        self_improve = insights['self_improvement_capacity']['health']
        
        insights['evolutionary_potential'] = (code_health + impl_depth + self_improve) / 3.0
        
        print(f"  Evolutionary Potential: {insights['evolutionary_potential']:.1%}")
        print()
        
        return insights
    
    def _assess_code_health(self) -> Dict:
        """Assess code health via TODO/FIXME/STUB markers"""
        print("  Scanning for code markers...")
        
        todo_count = 0
        fixme_count = 0
        stub_count = 0
        
        # Scan key directories
        for component_dir in self.repo_path.iterdir():
            if component_dir.is_dir() and not component_dir.name.startswith('.'):
                markers = self._count_markers_in_directory(component_dir)
                todo_count += markers['TODO']
                fixme_count += markers['FIXME']
                stub_count += markers['STUB']
        
        total_markers = todo_count + fixme_count + stub_count
        
        # Health is inverse of marker density (assume 3000 markers = 0% health)
        health = max(0.0, 1.0 - (total_markers / 3000.0))
        
        self.metrics.todo_count = todo_count
        self.metrics.fixme_count = fixme_count
        self.metrics.stub_count = stub_count
        self.metrics.total_code_markers = total_markers
        
        print(f"    TODO: {todo_count}, FIXME: {fixme_count}, STUB: {stub_count}")
        
        return {
            'todo_count': todo_count,
            'fixme_count': fixme_count,
            'stub_count': stub_count,
            'total_markers': total_markers,
            'health': health,
        }
    
    def _count_markers_in_directory(self, directory: Path) -> Dict[str, int]:
        """Count TODO/FIXME/STUB markers in a directory"""
        markers = {'TODO': 0, 'FIXME': 0, 'STUB': 0}
        
        if not directory.exists() or not directory.is_dir():
            return markers
        
        extensions = ['.cc', '.h', '.cpp', '.hpp', '.scm', '.py']
        
        for ext in extensions:
            for file_path in directory.rglob(f'*{ext}'):
                try:
                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                        content = f.read()
                        markers['TODO'] += len(re.findall(r'\bTODO\b', content, re.IGNORECASE))
                        markers['FIXME'] += len(re.findall(r'\bFIXME\b', content, re.IGNORECASE))
                        markers['STUB'] += len(re.findall(r'\bSTUB\b', content, re.IGNORECASE))
                except Exception:
                    pass
        
        return markers
    
    def _assess_implementation_depth(self) -> Dict:
        """Assess implementation completeness vs placeholders"""
        small_files = 0
        total_files = 0
        
        for cc_file in self.repo_path.rglob('*.cc'):
            total_files += 1
            if cc_file.stat().st_size < 500:  # Less than 500 bytes
                small_files += 1
        
        for scm_file in self.repo_path.rglob('*.scm'):
            total_files += 1
            if scm_file.stat().st_size < 200:  # Less than 200 bytes
                small_files += 1
        
        # Health is percentage of substantial files
        health = 1.0 - (small_files / total_files) if total_files > 0 else 1.0
        
        return {
            'total_implementation_files': total_files,
            'small_stub_files': small_files,
            'health': health,
        }
    
    def _assess_self_improvement_capacity(self) -> Dict:
        """Assess capacity for self-improvement and evolution"""
        # Check for meta-cognitive components
        meta_components = [
            self.repo_path / "cognitive_membrane_scanner.py",
            self.repo_path / "verify_implementations.py",
            self.repo_path / "dependency_analyzer.py",
            self.repo_path / "validate-integration.py",
            self.repo_path / "entelechy_introspection.py",
        ]
        
        present_count = sum(1 for c in meta_components if c.exists())
        
        # Check for autognosis-related documentation
        autognosis_doc = self.repo_path / ".github" / "agents" / "AUTOGNOSIS.md"
        ontogenesis_doc = self.repo_path / ".github" / "agents" / "ONTOGENESIS.md"
        
        has_autognosis = autognosis_doc.exists()
        has_ontogenesis = ontogenesis_doc.exists()
        
        # Health based on meta-cognitive tooling
        health = (present_count / len(meta_components)) * 0.7
        if has_autognosis:
            health += 0.15
        if has_ontogenesis:
            health += 0.15
        
        return {
            'meta_tools_present': present_count,
            'meta_tools_total': len(meta_components),
            'has_autognosis': has_autognosis,
            'has_ontogenesis': has_ontogenesis,
            'health': min(1.0, health),
        }
    
    def _calculate_entelechy_metrics(self):
        """Calculate holistic entelechy metrics"""
        print("ðŸ“ˆ Calculating Holistic Entelechy Metrics...")
        
        # Extract dimensional health scores
        ontological = self.dimensional_insights['ontological']['architectural_completeness']
        teleological = self.dimensional_insights['teleological']['actualization_trajectory']
        cognitive = self.dimensional_insights['cognitive']['cognitive_completeness']
        integrative = self.dimensional_insights['integrative']['integration_health']
        evolutionary = self.dimensional_insights['evolutionary']['evolutionary_potential']
        
        # Calculate main metrics
        self.metrics.completeness_score = ontological
        self.metrics.alignment_score = teleological
        self.metrics.coherence_score = integrative
        self.metrics.vitality_score = evolutionary
        
        # Actualization: Overall realization of potential (weighted average)
        self.metrics.actualization_score = (
            ontological * 0.2 +
            teleological * 0.25 +
            cognitive * 0.25 +
            integrative * 0.15 +
            evolutionary * 0.15
        )
        
        # Determine development stage
        self.metrics.development_stage = self.metrics.determine_stage()
        
        print(f"  Actualization Score: {self.metrics.actualization_score:.1%}")
        print(f"  Development Stage: {self.metrics.development_stage.value}")
        print()
    
    def _detect_fragmentations(self):
        """Detect fragmentations across all dimensions"""
        print("ðŸ” Detecting Fragmentations...")
        
        # Detect high-severity fragmentations based on code markers
        if self.metrics.total_code_markers > 2000:
            self.fragments.append(FragmentationSignature(
                dimension=EntelechyDimension.EVOLUTIONARY,
                fragmentation_type=FragmentationType.PLACEHOLDER_CODE,
                location="Repository-wide",
                severity=min(1.0, self.metrics.total_code_markers / 3000.0),
                description=f"High density of code markers ({self.metrics.total_code_markers} total)",
                repair_priority=8,
                repair_suggestions=[
                    "Systematically resolve TODO markers",
                    "Address FIXME issues",
                    "Replace STUB implementations with complete code"
                ]
            ))
        
        # Check for incomplete integration
        integration_health = self.dimensional_insights['integrative']['integration_health']
        if integration_health < 0.8:
            self.fragments.append(FragmentationSignature(
                dimension=EntelechyDimension.INTEGRATIVE,
                fragmentation_type=FragmentationType.INTEGRATION_GAP,
                location="Build and test systems",
                severity=1.0 - integration_health,
                description="Integration health below optimal threshold",
                repair_priority=7,
                repair_suggestions=[
                    "Improve CMake integration",
                    "Expand test coverage",
                    "Strengthen component dependencies"
                ]
            ))
        
        print(f"  Detected {len(self.fragments)} fragmentations")
        print()
    
    def _group_fragments_by_dimension(self) -> Dict:
        """Group fragments by entelechy dimension"""
        grouped = defaultdict(list)
        for fragment in self.fragments:
            grouped[fragment.dimension.value].append(self._fragment_to_dict(fragment))
        return dict(grouped)
    
    def _group_fragments_by_type(self) -> Dict:
        """Group fragments by fragmentation type"""
        grouped = defaultdict(list)
        for fragment in self.fragments:
            grouped[fragment.fragmentation_type.value].append(self._fragment_to_dict(fragment))
        return dict(grouped)
    
    def _get_critical_fragments(self) -> List[Dict]:
        """Get fragments with severity >= 0.7"""
        critical = [f for f in self.fragments if f.severity >= 0.7]
        return [self._fragment_to_dict(f) for f in sorted(critical, key=lambda x: x.severity, reverse=True)]
    
    def _fragment_to_dict(self, fragment: FragmentationSignature) -> Dict:
        """Convert fragment to dictionary"""
        return {
            'dimension': fragment.dimension.value,
            'type': fragment.fragmentation_type.value,
            'location': fragment.location,
            'severity': fragment.severity,
            'description': fragment.description,
            'repair_priority': fragment.repair_priority,
            'repair_suggestions': fragment.repair_suggestions,
        }
    
    def _generate_repair_roadmap(self) -> Dict:
        """Generate prioritized repair roadmap"""
        prioritized = sorted(self.fragments, key=lambda x: (x.repair_priority, x.severity), reverse=True)
        
        roadmap = {
            'immediate_actions': [],
            'short_term_actions': [],
            'medium_term_actions': [],
            'long_term_actions': [],
        }
        
        for fragment in prioritized:
            action = {
                'location': fragment.location,
                'type': fragment.fragmentation_type.value,
                'severity': fragment.severity,
                'description': fragment.description,
                'suggestions': fragment.repair_suggestions,
            }
            
            if fragment.severity >= 0.8:
                roadmap['immediate_actions'].append(action)
            elif fragment.severity >= 0.6:
                roadmap['short_term_actions'].append(action)
            elif fragment.severity >= 0.4:
                roadmap['medium_term_actions'].append(action)
            else:
                roadmap['long_term_actions'].append(action)
        
        return roadmap
    
    def _metrics_to_dict(self) -> Dict:
        """Convert metrics to dictionary"""
        return {
            'actualization_score': self.metrics.actualization_score,
            'coherence_score': self.metrics.coherence_score,
            'vitality_score': self.metrics.vitality_score,
            'completeness_score': self.metrics.completeness_score,
            'alignment_score': self.metrics.alignment_score,
            'fitness': self.metrics.fitness(),
            'development_stage': self.metrics.development_stage.value,
            'total_components': self.metrics.total_components,
            'integrated_components': self.metrics.integrated_components,
            'fragmented_components': self.metrics.fragmented_components,
            'total_code_markers': self.metrics.total_code_markers,
            'todo_count': self.metrics.todo_count,
            'fixme_count': self.metrics.fixme_count,
            'stub_count': self.metrics.stub_count,
        }
